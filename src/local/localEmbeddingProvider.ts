/**
 * Local embedding provider using Transformers.js for offline embedding generation
 * Provides fallback when OpenAI API key is not available
 */

import { logger } from '../utils/logger';

// Dynamic import for ESM-only transformers package
let transformersModule: any = null;

async function initializeTransformers() {
  if (!transformersModule) {
    try {
      transformersModule = await import('@xenova/transformers');
      logger.debug('‚úÖ @xenova/transformers loaded successfully');
    } catch (error) {
      logger.warn('‚ö†Ô∏è @xenova/transformers not available, local embeddings disabled', {
        error: error instanceof Error ? error.message : String(error),
      });
      throw new Error('Local embeddings not available: @xenova/transformers package could not be loaded');
    }
  }
  return transformersModule;
}

export interface EmbeddingResult {
  embedding: number[];
  model: string;
  dimensions: number;
}

export interface LocalEmbeddingConfig {
  model?:
    | 'all-MiniLM-L6-v2'
    | 'multilingual-e5-large'
    | 'all-mpnet-base-v2'
    | 'advanced-neural-dense';
    // Note: multilingual-e5-large-instruct is not available in Xenova Transformers
  maxLength?: number;
  normalize?: boolean;
  pooling?: 'mean' | 'cls';
}

export class LocalEmbeddingProvider {
  private pipeline: any | null = null;
  private model: string;
  private dimensions: number;
  private config: Required<LocalEmbeddingConfig>;

  constructor(config: LocalEmbeddingConfig = {}) {
    this.config = {
      model: config.model || this.getDefaultModel(),
      maxLength: config.maxLength || 512,
      normalize: config.normalize ?? true,
      pooling: config.pooling || 'mean',
    };

    this.model = `Xenova/${this.mapModelName(this.config.model)}`;
    this.dimensions = this.getModelDimensions();
  }

  private getModelDimensions(): number {
    switch (this.config.model) {
      case 'all-MiniLM-L6-v2':
        return 384; // Standard expected dimensions
      case 'all-mpnet-base-v2':
      case 'advanced-neural-dense':
        return 768; // Standard expected dimensions
      case 'multilingual-e5-large':
        return 1024; // Actual dimensions returned by Xenova/multilingual-e5-large
      default:
        return 384;
    }
  }

  /**
   * Get the default model based on environment variable or fallback
   */
  private getDefaultModel():
    | 'all-MiniLM-L6-v2'
    | 'multilingual-e5-large'
    | 'all-mpnet-base-v2'
    | 'advanced-neural-dense' {
    const envModel = process.env.LOCAL_EMBEDDING_MODEL;
    if (envModel) {
      // Validate the environment variable value
      switch (envModel.toLowerCase()) {
        case 'all-minilm-l6-v2':
          return 'all-MiniLM-L6-v2';
        case 'multilingual-e5-large':
          return 'multilingual-e5-large';
        case 'all-mpnet-base-v2':
          return 'all-mpnet-base-v2';
        case 'advanced-neural-dense':
          return 'advanced-neural-dense';
        default:
          logger.warn(
            `‚ö†Ô∏è Unknown LOCAL_EMBEDDING_MODEL value: ${envModel}, using all-MiniLM-L6-v2`
          );
          return 'all-MiniLM-L6-v2';
      }
    }
    return 'all-MiniLM-L6-v2'; // Default fallback
  }

  /**
   * Map our model names to Xenova/Transformers model names
   */
  private mapModelName(model: string): string {
    switch (model) {
      case 'advanced-neural-dense':
        return 'all-mpnet-base-v2'; // Advanced Neural Dense Retrieval model
      case 'multilingual-e5-large-instruct':
        return 'multilingual-e5-large-instruct'; // Instruction-tuned multilingual model
      default:
        return model;
    }
  }

  /**
   * Initialize the embedding pipeline (lazy loading)
   */
  private async initializePipeline(): Promise<void> {
    if (this.pipeline) {
      return;
    }

    try {
      logger.info('ü§ñ Initializing local embedding model', {
        model: this.model,
        dimensions: this.dimensions,
      });

      // Dynamically import transformers if not already loaded
      const transformers = await initializeTransformers();

      // Load the feature extraction pipeline
      this.pipeline = await transformers.pipeline('feature-extraction', this.model, {
        // Use local cache to avoid re-downloading models
        local_files_only: false,
        revision: 'main',
      });

      logger.info('‚úÖ Local embedding model loaded successfully', {
        model: this.config.model,
      });
    } catch (error) {
      logger.error('‚ùå Failed to load local embedding model', {
        model: this.config.model,
        error: error instanceof Error ? error.message : String(error),
      });
      throw new Error(`Failed to initialize local embedding model: ${error}`);
    }
  }

  /**
   * Generate embeddings for text chunks
   */
  async generateEmbeddings(texts: string[]): Promise<EmbeddingResult[]> {
    if (texts.length === 0) {
      return [];
    }

    // Filter out empty or whitespace-only strings
    const validTexts = texts.filter(text => text && text.trim().length > 0);

    if (validTexts.length === 0) {
      logger.warn('‚ö†Ô∏è No valid texts provided for embedding generation');
      return [];
    }

    // Log input validation
    logger.debug('üîç Input validation for embeddings', {
      originalCount: texts.length,
      validCount: validTexts.length,
      avgLength: Math.round(validTexts.reduce((sum, text) => sum + text.length, 0) / validTexts.length),
      sampleText: validTexts[0]?.substring(0, 100) + (validTexts[0]?.length > 100 ? '...' : ''),
    });

    await this.initializePipeline();

    if (!this.pipeline) {
      throw new Error('Failed to initialize embedding pipeline');
    }

    try {
      logger.debug('üîÑ Generating embeddings with local model', {
        model: this.config.model,
        textCount: validTexts.length,
        avgLength: Math.round(
          validTexts.reduce((sum, text) => sum + text.length, 0) / validTexts.length
        ),
      });

      // Truncate texts that are too long
      const truncatedTexts = validTexts.map(text =>
        text.length > this.config.maxLength * 4 // Rough char to token ratio
          ? text.substring(0, this.config.maxLength * 4)
          : text
      );

      // Generate embeddings - handle multilingual-e5-large specially
      let embeddings: any;

      // Process texts individually to avoid batch processing issues
      // This appears to be a fundamental limitation of the Transformers.js models
      logger.info('üîÑ Processing texts individually to avoid batch processing issues');
      const individualResults = [];

      for (const text of truncatedTexts) {
        try {
          const singleResult = await this.pipeline([text], {
            pooling: this.config.pooling,
            normalize: this.config.normalize,
          });

          if (Array.isArray(singleResult) && singleResult.length > 0) {
            individualResults.push(singleResult[0]);
          } else if (singleResult && typeof singleResult === 'object' && 'data' in singleResult) {
            individualResults.push(singleResult);
          } else {
            logger.warn('‚ö†Ô∏è Unexpected single result format', {
              resultType: typeof singleResult,
              model: this.config.model,
            });
            // Skip this result rather than failing completely
            continue;
          }
        } catch (singleTextError) {
          logger.warn('‚ö†Ô∏è Failed to process individual text', {
            error: singleTextError instanceof Error ? singleTextError.message : String(singleTextError),
            model: this.config.model,
          });
          // Skip this result rather than failing completely
          continue;
        }
      }

      if (individualResults.length === 0) {
        throw new Error('No texts could be processed successfully');
      }

      embeddings = individualResults;

      // For individual processing, we need to adjust the validation
      // since we're now processing texts individually, the result should have the right count
      logger.debug('üîç Pipeline returned:', {
        type: typeof embeddings,
        isArray: Array.isArray(embeddings),
        length: Array.isArray(embeddings) ? embeddings.length : 'N/A',
        constructor: embeddings?.constructor?.name,
        firstItem: Array.isArray(embeddings) && embeddings.length > 0 ? {
          type: typeof embeddings[0],
          keys: embeddings[0] ? Object.keys(embeddings[0]) : 'null/undefined',
          hasData: embeddings[0] && 'data' in embeddings[0],
          dataType: embeddings[0]?.data ? typeof embeddings[0].data : 'N/A',
          dataLength: embeddings[0]?.data ? embeddings[0].data.length : 'N/A',
          // Check if it's a tensor or other complex object
          isTensor: embeddings[0]?.data?.constructor?.name,
        } : 'no items',
        truncatedTextsCount: truncatedTexts.length,
        model: this.config.model,
      });

      // Handle different response formats
      let embeddingArray: any[];

      if (!Array.isArray(embeddings)) {
        // If it's not an array, it might be a single result
        if (embeddings && typeof embeddings === 'object' && 'data' in embeddings) {
          logger.debug('üìù Single embedding result detected, wrapping in array');
          embeddingArray = [embeddings];
        } else {
          throw new Error(`Pipeline returned invalid embeddings: expected array or object with data, got ${typeof embeddings}`);
        }
      } else {
        // embeddings is already an array
        embeddingArray = embeddings;
      }

      // Ensure each result has the expected format
      for (let i = 0; i < embeddingArray.length; i++) {
        const result = embeddingArray[i];
        if (result && result.data && result.data.length !== this.getModelDimensions()) {
          logger.warn(`‚ö†Ô∏è Result ${i} has unexpected dimensions`, {
            expected: this.getModelDimensions(),
            actual: result.data.length,
            model: this.config.model,
          });
        }
      }

      // Validate embeddings response
      if (embeddingArray.length === 0) {
        throw new Error('Pipeline returned empty embeddings array');
      }

      if (embeddingArray.length !== validTexts.length) {
        logger.warn('‚ö†Ô∏è Result count mismatch', {
          expected: validTexts.length,
          actual: embeddingArray.length,
          model: this.config.model,
        });

        // If we have more results than expected, truncate
        if (embeddingArray.length > validTexts.length) {
          embeddingArray = embeddingArray.slice(0, validTexts.length);
        }
        // If we have fewer results than expected, this indicates processing errors
        // but continue with what we have rather than failing completely
      }

      // Convert to our standard format
      const results: EmbeddingResult[] = [];

      for (let i = 0; i < embeddingArray.length; i++) {
        if (!embeddingArray[i]) {
          throw new Error(`Invalid embedding result at index ${i}: null/undefined`);
        }

        if (!embeddingArray[i].data) {
          logger.warn('‚ö†Ô∏è Embedding result missing data property, checking for direct array', {
            index: i,
            embeddingType: typeof embeddingArray[i],
            embeddingKeys: Object.keys(embeddingArray[i] || {}),
          });

          // Try to handle different response formats
          if (Array.isArray(embeddingArray[i])) {
            // If it's directly an array, use it as the embedding
            const embedding = Array.from(embeddingArray[i] as number[]);
            if (embedding.length === 0) {
              throw new Error(`Invalid embedding result at index ${i}: empty embedding array`);
            }
            results.push({
              embedding,
              model: this.config.model,
              dimensions: embedding.length,
            });
            continue;
          }

          throw new Error(`Invalid embedding result at index ${i}: missing data property and not a direct array`);
        }

        const embedding = Array.from(embeddingArray[i].data as Float32Array);
        if (!embedding || embedding.length === 0) {
          throw new Error(`Invalid embedding result at index ${i}: empty embedding`);
        }

        results.push({
          embedding,
          model: this.config.model,
          dimensions: embedding.length,
        });
      }

      logger.debug('‚úÖ Local embeddings generated successfully', {
        model: this.config.model,
        count: results.length,
        dimensions: results[0]?.dimensions,
      });

      return results;
    } catch (error) {
      logger.error('‚ùå Failed to generate local embeddings', {
        model: this.config.model,
        textCount: texts.length,
        error: error instanceof Error ? error.message : String(error),
      });
      throw new Error(`Failed to generate embeddings: ${error}`);
    }
  }

  /**
   * Generate embedding for a single text
   */
  async generateEmbedding(text: string): Promise<EmbeddingResult> {
    const results = await this.generateEmbeddings([text]);
    if (results.length === 0) {
      throw new Error('Failed to generate embedding');
    }
    return results[0];
  }

  /**
   * Get model information
   */
  getModelInfo() {
    return {
      name: this.config.model, // Return plain model name without Xenova prefix for tests
      provider: 'transformers.js',
      dimensions: this.dimensions,
      maxLength: this.config.maxLength,
      offline: true,
    };
  }

  /**
   * Cleanup resources
   */
  async dispose(): Promise<void> {
    if (this.pipeline) {
      // Transformers.js handles cleanup automatically
      this.pipeline = null;
      logger.debug('üßπ Local embedding pipeline disposed');
    }
  }
}

// Singleton instance for global use
let defaultProvider: LocalEmbeddingProvider | null = null;

export function getDefaultLocalProvider(config?: LocalEmbeddingConfig): LocalEmbeddingProvider {
  if (!defaultProvider) {
    // If no config provided and we have LOCAL_EMBEDDING_MODEL set, use it
    if (!config && process.env.LOCAL_EMBEDDING_MODEL) {
      const envModel = process.env.LOCAL_EMBEDDING_MODEL.toLowerCase();
      let modelName:
        | 'all-MiniLM-L6-v2'
        | 'multilingual-e5-large'
        | 'all-mpnet-base-v2'
        | 'advanced-neural-dense' = 'all-MiniLM-L6-v2';

      switch (envModel) {
        case 'all-minilm-l6-v2':
          modelName = 'all-MiniLM-L6-v2';
          break;
        case 'multilingual-e5-large':
          modelName = 'multilingual-e5-large';
          break;
        case 'all-mpnet-base-v2':
          modelName = 'all-mpnet-base-v2';
          break;
        case 'advanced-neural-dense':
          modelName = 'advanced-neural-dense';
          break;
        default:
          logger.warn(
            `‚ö†Ô∏è Unknown LOCAL_EMBEDDING_MODEL value: ${process.env.LOCAL_EMBEDDING_MODEL}, using all-MiniLM-L6-v2`
          );
      }

      defaultProvider = new LocalEmbeddingProvider({ model: modelName });
      logger.info('ü§ñ Local embedding provider initialized from environment variable', {
        model: modelName,
        envVar: process.env.LOCAL_EMBEDDING_MODEL,
      });
    } else {
      defaultProvider = new LocalEmbeddingProvider(config);
    }
  }
  return defaultProvider;
}

export async function disposeDefaultProvider(): Promise<void> {
  if (defaultProvider) {
    await defaultProvider.dispose();
    defaultProvider = null;
  }
}
